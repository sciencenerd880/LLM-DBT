{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIXIXyyUnNF6"
   },
   "source": [
    "# N01-Transcript_to_facts\n",
    "*Purpose*: To convert raw extracted shark tank episode transcripts (from derrick) into facts dictionary which contains 5 portion. The 5 portion can then be used as our dataset for downstream models\n",
    "\n",
    "    1. Facts about the company or product that are hard quantifiable facts\n",
    "    2. Product description\n",
    "    3. Summary of investor pitch. This should contain information about how the pitch was delivered, the sentiment, the story, and other aspects essential to the pitch.\n",
    "    4. Entrepreneur initial offer\n",
    "    5. Final agreed offer by the shark investor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1530,
     "status": "ok",
     "timestamp": 1741437313743,
     "user": {
      "displayName": "Lim Kaizhuo",
      "userId": "06807019367334995066"
     },
     "user_tz": -480
    },
    "id": "a2B1icxPqoWI",
    "outputId": "b8b59a53-56e5-4909-adb6-7a624aa4b114"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
      "/content/gdrive/MyDrive/MITB/CS6xx LLM/LLM Project\n"
     ]
    }
   ],
   "source": [
    "# run this cell if using google colab (kaizhuo G drive)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')\n",
    "%cd /content/gdrive/MyDrive/MITB/CS6xx\\ LLM/LLM\\ Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 135273,
     "status": "ok",
     "timestamp": 1741436249799,
     "user": {
      "displayName": "Lim Kaizhuo",
      "userId": "06807019367334995066"
     },
     "user_tz": -480
    },
    "id": "Vc0Io8ACnNF-",
    "outputId": "8049484b-eedb-4ac9-ec9e-cf0e69d0a775"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
      "Collecting together\n",
      "  Downloading together-1.4.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from together) (8.1.8)\n",
      "Collecting eval-type-backport<0.3.0,>=0.1.3 (from together)\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from together) (11.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from together) (2.10.6)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /usr/local/lib/python3.11/dist-packages (from together) (13.9.4)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from together) (0.9.0)\n",
      "Requirement already satisfied: typer<0.16,>=0.9 in /usr/local/lib/python3.11/dist-packages (from together) (0.15.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.8.1->together) (2.18.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading together-1.4.1-py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.5/80.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, eval-type-backport, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, together, datasets, evaluate\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed datasets-3.3.2 dill-0.3.8 eval-type-backport-0.2.2 evaluate-0.4.3 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 together-1.4.1 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets evaluate torch accelerate datasets together openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 39043,
     "status": "ok",
     "timestamp": 1741436296903,
     "user": {
      "displayName": "Lim Kaizhuo",
      "userId": "06807019367334995066"
     },
     "user_tz": -480
    },
    "id": "44SRKmFUnNGA"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from torch.nn import functional as F\n",
    "from transformers import AutoTokenizer\n",
    "from together import Together\n",
    "from openai import OpenAI\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 554,
     "status": "ok",
     "timestamp": 1741436299603,
     "user": {
      "displayName": "Lim Kaizhuo",
      "userId": "06807019367334995066"
     },
     "user_tz": -480
    },
    "id": "1TtmeQKHnNGA"
   },
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"sk-5fb8c6b1d15f4ab1bb4e218980869d8c\", base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "def transcript_to_facts(transcript):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "            {\"role\": \"system\",\n",
    "            \"content\":\n",
    "            \"\"\"\n",
    "    In this transcript of a shark tank episode, can you extract out this 4 category of information?\n",
    "\n",
    "    1. Facts about the company or product that are hard quantifiable facts\n",
    "    2. Product description\n",
    "    3. Summary of investor pitch. This should contain information about how the pitch was delivered, the sentiment, the story, and other aspects essential to the pitch.\n",
    "    4. Entrepreneur initial offer\n",
    "    5. Final agreed offer by the shark investor\n",
    "\n",
    "    Convert it into a json format.\n",
    "\n",
    "    The transcript is below:\n",
    "    \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": transcript},\n",
    "        ],\n",
    "        stream=False\n",
    "    )\n",
    "    response = response.choices[0].message.content\n",
    "    response = json.loads(response.strip(\"```json\\n\").strip(\"```\"))\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 772,
     "status": "ok",
     "timestamp": 1741437318009,
     "user": {
      "displayName": "Lim Kaizhuo",
      "userId": "06807019367334995066"
     },
     "user_tz": -480
    },
    "id": "w9OGF5ebnNGB",
    "outputId": "16993354-cf08-4a59-8c6d-d09c9c8ce4f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: shark_tank_transcript_0_TouchUp Cup.txt\n",
      "shark_tank_transcript_0_TouchUp Cup.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_0_Roadie.txt\n",
      "shark_tank_transcript_0_Roadie.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_0_GarmaGuard.txt\n",
      "shark_tank_transcript_0_GarmaGuard.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_1_BootayBag.txt\n",
      "shark_tank_transcript_1_BootayBag.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_1_GoOats.txt\n",
      "shark_tank_transcript_1_GoOats.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_3_Electra.txt\n",
      "shark_tank_transcript_3_Electra.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_3_All33.txt\n",
      "shark_tank_transcript_3_All33.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_3_His & Her Bar.txt\n",
      "shark_tank_transcript_3_His & Her Bar.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_3_TrophySmack.txt\n",
      "shark_tank_transcript_3_TrophySmack.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_4_Brumachen.txt\n",
      "shark_tank_transcript_4_Brumachen.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_4_Aura Bora.txt\n",
      "shark_tank_transcript_4_Aura Bora.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_4_SwipenSnap.txt\n",
      "shark_tank_transcript_4_SwipenSnap.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_5_Grind Machine.txt\n",
      "shark_tank_transcript_5_Grind Machine.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_5_SneakErasers.txt\n",
      "shark_tank_transcript_5_SneakErasers.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_5_BeerMKR.txt\n",
      "shark_tank_transcript_5_BeerMKR.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_6_Frobert.txt\n",
      "shark_tank_transcript_6_Frobert.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_6_Float'N'Grill.txt\n",
      "shark_tank_transcript_6_Float'N'Grill.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_6_The Original Stretchlace.txt\n",
      "shark_tank_transcript_6_The Original Stretchlace.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_7_Copper Cow Coffee.txt\n",
      "shark_tank_transcript_7_Copper Cow Coffee.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_7_LIT Handlers.txt\n",
      "shark_tank_transcript_7_LIT Handlers.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_7_Super Potty Trainer.txt\n",
      "shark_tank_transcript_7_Super Potty Trainer.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_8_TheMagic5.txt\n",
      "shark_tank_transcript_8_TheMagic5.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_8_Tabby.txt\n",
      "shark_tank_transcript_8_Tabby.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_8_SoaPen.txt\n",
      "shark_tank_transcript_8_SoaPen.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_8_54 Thrones.txt\n",
      "shark_tank_transcript_8_54 Thrones.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_9_SPERGO.txt\n",
      "shark_tank_transcript_9_SPERGO.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_10_Fish Fixe.txt\n",
      "shark_tank_transcript_10_Fish Fixe.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_10_Deux.txt\n",
      "shark_tank_transcript_10_Deux.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_10_Hidrent.txt\n",
      "shark_tank_transcript_10_Hidrent.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_11_Sheets Laundry Club.txt\n",
      "shark_tank_transcript_11_Sheets Laundry Club.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_11_Pink Picasso.txt\n",
      "shark_tank_transcript_11_Pink Picasso.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_11_Love & Pebble.txt\n",
      "shark_tank_transcript_11_Love & Pebble.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_11_Zach & Zoe Sweet Bee Farm.txt\n",
      "shark_tank_transcript_11_Zach & Zoe Sweet Bee Farm.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_12_Wendy's Gnome Shop.txt\n",
      "shark_tank_transcript_12_Wendy's Gnome Shop.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_12_Ornament Anchor.txt\n",
      "shark_tank_transcript_12_Ornament Anchor.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_13_MAXPRO SmartConnect.txt\n",
      "shark_tank_transcript_13_MAXPRO SmartConnect.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_13_Banana Loca.txt\n",
      "shark_tank_transcript_13_Banana Loca.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_14_Snactiv.txt\n",
      "shark_tank_transcript_14_Snactiv.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_14_The SMART Tire Company.txt\n",
      "shark_tank_transcript_14_The SMART Tire Company.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_14_Candi.txt\n",
      "shark_tank_transcript_14_Candi.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_14_Black Sands Entertainment.txt\n",
      "shark_tank_transcript_14_Black Sands Entertainment.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_15_VaBroom.txt\n",
      "shark_tank_transcript_15_VaBroom.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_15_Headlightz.txt\n",
      "shark_tank_transcript_15_Headlightz.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_16_Tania Speaks Organic Skincare.txt\n",
      "shark_tank_transcript_16_Tania Speaks Organic Skincare.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_16_TA3.txt\n",
      "shark_tank_transcript_16_TA3.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_16_Tristen Ikaika.txt\n",
      "shark_tank_transcript_16_Tristen Ikaika.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_17_Kettle Gryp.txt\n",
      "shark_tank_transcript_17_Kettle Gryp.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_17_Calm Strips.txt\n",
      "shark_tank_transcript_17_Calm Strips.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_18_Curie.txt\n",
      "shark_tank_transcript_18_Curie.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_18_NOGGIN Boss.txt\n",
      "shark_tank_transcript_18_NOGGIN Boss.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_18_Behave Bras.txt\n",
      "shark_tank_transcript_18_Behave Bras.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_18_Ade + Ayo.txt\n",
      "shark_tank_transcript_18_Ade + Ayo.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_19_SUNFLOW.txt\n",
      "shark_tank_transcript_19_SUNFLOW.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_19_Chapul.txt\n",
      "shark_tank_transcript_19_Chapul.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_19_ootBox.txt\n",
      "shark_tank_transcript_19_ootBox.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_19_Do Amore.txt\n",
      "shark_tank_transcript_19_Do Amore.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_20_Stryx.txt\n",
      "shark_tank_transcript_20_Stryx.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_20_Drifties.txt\n",
      "shark_tank_transcript_20_Drifties.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_20_Springer.txt\n",
      "shark_tank_transcript_20_Springer.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_20_Chill-N-Reel.txt\n",
      "shark_tank_transcript_20_Chill-N-Reel.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_2_Prime 6.txt\n",
      "shark_tank_transcript_2_Prime 6.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_21_Kent.txt\n",
      "shark_tank_transcript_21_Kent.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_21_Oogiebear.txt\n",
      "shark_tank_transcript_21_Oogiebear.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_22_The Woobles.txt\n",
      "shark_tank_transcript_22_The Woobles.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_22_Banana Phone.txt\n",
      "shark_tank_transcript_22_Banana Phone.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_22_Turbo Trusser.txt\n",
      "shark_tank_transcript_22_Turbo Trusser.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_22_Stealth Bros & Co..txt\n",
      "shark_tank_transcript_22_Stealth Bros & Co..txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_23_Pumpkin Glove Scraper.txt\n",
      "shark_tank_transcript_23_Pumpkin Glove Scraper.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_23_Stakt.txt\n",
      "shark_tank_transcript_23_Stakt.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_23_Mama O's Premium Kimchi.txt\n",
      "shark_tank_transcript_23_Mama O's Premium Kimchi.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_23_Create A Castle.txt\n",
      "shark_tank_transcript_23_Create A Castle.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_24_Storage Scholars.txt\n",
      "shark_tank_transcript_24_Storage Scholars.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_24_Woosh.txt\n",
      "shark_tank_transcript_24_Woosh.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_25_Plufl.txt\n",
      "shark_tank_transcript_25_Plufl.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_25_Bridal Babes.txt\n",
      "shark_tank_transcript_25_Bridal Babes.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_26_Collars & Co..txt\n",
      "shark_tank_transcript_26_Collars & Co..txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_26_SquareOne.txt\n",
      "shark_tank_transcript_26_SquareOne.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_27_Boarderie.txt\n",
      "shark_tank_transcript_27_Boarderie.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_27_Ride FRSH.txt\n",
      "shark_tank_transcript_27_Ride FRSH.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_28_HummViewer.txt\n",
      "shark_tank_transcript_28_HummViewer.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_28_ShredSkinz.txt\n",
      "shark_tank_transcript_28_ShredSkinz.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_29_ZipString.txt\n",
      "shark_tank_transcript_29_ZipString.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_29_ChessUp.txt\n",
      "shark_tank_transcript_29_ChessUp.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_30_Eat Your Flowers.txt\n",
      "shark_tank_transcript_30_Eat Your Flowers.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_30_Foam Party Hats.txt\n",
      "shark_tank_transcript_30_Foam Party Hats.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_31_Pluie.txt\n",
      "shark_tank_transcript_31_Pluie.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_31_Flated.txt\n",
      "shark_tank_transcript_31_Flated.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_31_Woof.txt\n",
      "shark_tank_transcript_31_Woof.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_31_Sweetkiwi.txt\n",
      "shark_tank_transcript_31_Sweetkiwi.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_32_Crispy Cones.txt\n",
      "shark_tank_transcript_32_Crispy Cones.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_32_Chubby Buttons.txt\n",
      "shark_tank_transcript_32_Chubby Buttons.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_32_Autio.txt\n",
      "shark_tank_transcript_32_Autio.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_32_Tngnt Ski Bikes.txt\n",
      "shark_tank_transcript_32_Tngnt Ski Bikes.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_33_LavaBox Portable Campfires.txt\n",
      "shark_tank_transcript_33_LavaBox Portable Campfires.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_33_Bleni Blends.txt\n",
      "shark_tank_transcript_33_Bleni Blends.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_33_Happi Floss.txt\n",
      "shark_tank_transcript_33_Happi Floss.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_33_The Ice Cream Canteen.txt\n",
      "shark_tank_transcript_33_The Ice Cream Canteen.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_34_Parting Stone.txt\n",
      "shark_tank_transcript_34_Parting Stone.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_34_Cincha Travel Belt.txt\n",
      "shark_tank_transcript_34_Cincha Travel Belt.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_35_Honey Bunchies.txt\n",
      "shark_tank_transcript_35_Honey Bunchies.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_35_Dapper Boi.txt\n",
      "shark_tank_transcript_35_Dapper Boi.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_35_Play Maysie.txt\n",
      "shark_tank_transcript_35_Play Maysie.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_35_Tia Lupita.txt\n",
      "shark_tank_transcript_35_Tia Lupita.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_36_Nature's Wild Berry.txt\n",
      "shark_tank_transcript_36_Nature's Wild Berry.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_36_Collars & Co..txt\n",
      "shark_tank_transcript_36_Collars & Co..txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_36_Noshi.txt\n",
      "shark_tank_transcript_36_Noshi.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_36_You Go Natural.txt\n",
      "shark_tank_transcript_36_You Go Natural.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_37_Krapp Strapp.txt\n",
      "shark_tank_transcript_37_Krapp Strapp.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_37_Mini Materials.txt\n",
      "shark_tank_transcript_37_Mini Materials.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_37_TIK PIK.txt\n",
      "shark_tank_transcript_37_TIK PIK.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_37_Supermix Studio.txt\n",
      "shark_tank_transcript_37_Supermix Studio.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_38_Bunny Eyez.txt\n",
      "shark_tank_transcript_38_Bunny Eyez.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_38_The Fidget Game.txt\n",
      "shark_tank_transcript_38_The Fidget Game.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_1_Pooch Paper.txt\n",
      "shark_tank_transcript_1_Pooch Paper.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_11_Dude Wipes.txt\n",
      "shark_tank_transcript_11_Dude Wipes.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_12_Elf Grams.txt\n",
      "shark_tank_transcript_12_Elf Grams.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_12_Santa's Enchanted Mailbox.txt\n",
      "shark_tank_transcript_12_Santa's Enchanted Mailbox.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_13_Liberate.txt\n",
      "shark_tank_transcript_13_Liberate.txt has already been processed, skipping ... ...\n",
      "Processing: shark_tank_transcript_13_Tenikle.txt\n",
      "shark_tank_transcript_13_Tenikle.txt has already been processed, skipping ... ...\n"
     ]
    }
   ],
   "source": [
    "# read all transcripts available\n",
    "folder_path = Path(\"./Prelim_Data_Split_Clean\")\n",
    "transcript_store = {}\n",
    "for file in folder_path.glob(\"*.txt\"):\n",
    "    with file.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        transcript_store[file.name] = f.read()\n",
    "\n",
    "# read all facts that has already been processed (so as to avoid processing them again)\n",
    "facts_store = {}\n",
    "folder_path = Path(\"./facts\")\n",
    "for file in folder_path.glob(\"*.txt\"):\n",
    "    with file.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        facts_store[file.name] = f.read()\n",
    "\n",
    "# loop through each transcript, check that it is not in the facts folder, then process them\n",
    "facts_file_path = './facts'\n",
    "for transcript_name, transcript in transcript_store.items():\n",
    "    print(f'Processing: {transcript_name}')\n",
    "    if f'facts_{transcript_name}' in facts_store:\n",
    "        print(f'{transcript_name} has already been processed, skipping ... ...')\n",
    "        continue\n",
    "    else:\n",
    "        timenow = time.time()\n",
    "        facts = transcript_to_facts(transcript)\n",
    "        print(f'Saving facts: {transcript_name}. Latency: {time.time()-timenow}')\n",
    "        with open(f'{facts_file_path}/facts_{transcript_name}', \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump(facts, file, indent=4)  # `indent=4` makes it readable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1741437348611,
     "user": {
      "displayName": "Lim Kaizhuo",
      "userId": "06807019367334995066"
     },
     "user_tz": -480
    },
    "id": "fBZihhvkoMWh",
    "outputId": "48a16717-1e9a-42aa-b389-25d5f81417d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transcript_store)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "kz2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
