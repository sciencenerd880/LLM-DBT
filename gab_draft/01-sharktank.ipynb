{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shark Tank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os, json, re\n",
    "import random\n",
    "import asyncio\n",
    "import pandas as pd, numpy as np\n",
    "from tqdm import tqdm\n",
    "from sharktank_utils import *\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "from together import AsyncTogether, Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_folder = './scenario_basic_deepseek_R1'\n",
    "fact_path = 'facts_shark_tank_transcript_28_HummViewer.txt'\n",
    "scenario_name = \"_\".join(fact_path.split('_')[1:])\n",
    "\n",
    "# Read the facts\n",
    "facts_store = load_facts()\n",
    "# fact_dict = facts_store[fact_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GROQ_API_KEY', 'TOGETHER_API_KEY']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_api_key = os.environ['GROQ_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiAgent Functions\n",
    "- Multiagent Framework #1\n",
    "> Prompt --> Orchestrator --> N * Agents --> Aggregator --> Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model array\n",
    "reference_models = [\n",
    "    \"Gryphe/MythoMax-L2-13b-Lite\",\n",
    "    \"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\", # Free\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\", # Free\n",
    "    \"scb10x/scb10x-llama3-1-typhoon-18370\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\", # Free\n",
    "    'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo'\n",
    "]\n",
    "aggregator_model = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "evaluator_model = \"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\"\n",
    "\n",
    "# Set the system level prompt\n",
    "NUM_AGENTS = 3\n",
    "taskmaster_system_prompt = f\"\"\"\n",
    "You are a sharktank pitch director. You will take control {NUM_AGENTS} other LLM agents like yourself. \n",
    "You will be given a fact_dict containing the key facts of the product you will be creating the pitch for.\n",
    "Breakdown the task into 3 tasks and assign each portion to each LLM agent.\n",
    "Output your answer in a messages list that can be parsed by python's `eval()`. For example: \n",
    "{{\n",
    "    \"agent1\" : [{{\"role\":\"system\", \"content\":\"<insert role>\"}}, {{\"role\":\"user\",\"content\":\"<insert prompt>\"}}],\n",
    "    \"agent2\" : [{{\"role\":\"system\", \"content\":\"<insert role>\"}}, {{\"role\":\"user\",\"content\":\"<insert prompt>\"}}],\n",
    "    \"agent3\" : [{{\"role\":\"system\", \"content\":\"<insert role>\"}}, {{\"role\":\"user\",\"content\":\"<insert prompt>\"}}],\n",
    "}}\n",
    "Create winning pitches! No hallucinations! No explanations of the pitch!\n",
    "\"\"\"\n",
    "aggregator_system_prompt  = \"\"\"\n",
    "You have been provided with a set of responses from various open-source models to the latest user query. \n",
    "Your task is to synthesize these responses into a single, high-quality response. Output a script for prospective entrepreneurs to use.\n",
    "It is crucial to critically evaluate the information provided in these responses,\n",
    "recognizing that some of it may be biased or incorrect. \n",
    "Your response should not simply replicate the given answers but should offer a refined, accurate, and comprehensive reply to the instruction. \n",
    "Ensure your response is well-structured, coherent, and adheres to the highest standards of accuracy and reliability.\n",
    "Responses from models:\"\"\"\n",
    "\n",
    "# Define the client for use\n",
    "client = Together(\n",
    "    api_key=\"cfdb186041125ce240c532fd6f26db63bde4cb3811118f52e47508e5f0398836\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_prompt(facts):\n",
    "    return f\"\"\"\n",
    "My name is Paul McCarthney\n",
    "Here are the facts of my product: {facts}\n",
    "\"\"\"\n",
    "\n",
    "def select_models(num_agents=NUM_AGENTS, reference_models=reference_models):\n",
    "    return random.choices(reference_models, k=num_agents)\n",
    "\n",
    "def generate_pitch(facts, num_agents=NUM_AGENTS, reference_models=reference_models):\n",
    "    \"\"\"Run the main loop of the MOA process.\"\"\"\n",
    "    prompt = generate_user_prompt(facts)\n",
    "    assignments = eval(run_llm(\n",
    "        client=client,\n",
    "        model=aggregator_model,\n",
    "        system_prompt=taskmaster_system_prompt,\n",
    "        user_prompt=prompt\n",
    "    ))\n",
    "    assignments_list = list(assignments.values())\n",
    "\n",
    "    results = [run_llm(\n",
    "        client=client,\n",
    "        model=reference_models[i],\n",
    "        system_prompt=assignments_list[i][0]['content'],\n",
    "        user_prompt=assignments_list[i][1]['content']\n",
    "    ) for i in range(num_agents)]\n",
    "\n",
    "    final_pitch = client.chat.completions.create(\n",
    "        model=aggregator_model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\",\"content\": aggregator_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": aggregate_results(results, prompt)},\n",
    "        ]\n",
    "    )\n",
    "    return final_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionResponse(id='nmEXmNA-3NKUce-9213db5a3e3e91b7', object=<ObjectType.ChatCompletion: 'chat.completion'>, created=1742123979, model='mistralai/Mistral-7B-Instruct-v0.3', choices=[ChatCompletionChoicesData(index=0, logprobs=None, seed=2101572877195609300, finish_reason=<FinishReason.StopSequence: 'stop'>, message=ChatCompletionMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=' {\\n  \"pitch\": {\\n    \"delivery\": \"The entrepreneurs, Pete and Bianca, presented their pitch with a narrative involving a character named Joe, illustrating the daily exposure to germs and the lack of solutions for cleaning clothes on the go. They used a demonstration to show the product\\'s effectiveness. The pitch was delivered with enthusiasm and a clear passion for solving a real-world problem. The entrepreneurs were confident and engaged the Sharks with a story that highlighted the necessity of their product.\",\\n    \"sentiment\": \"The pitch was delivered with enthusiasm and a clear passion for solving a real-world problem. The entrepreneurs were confident and engaged the Sharks with a story that highlighted the necessity of their product.\",\\n    \"story\": \"The idea for GarmaGuard came from Bianca\\'s experience as a nurse, feeling the need for a product to clean clothes exposed to germs and bacteria throughout the day. They emphasized the product\\'s natural ingredients and its effectiveness in eliminating odors and bacteria.\",\\n    \"key_aspects\": \"The pitch focused on the product\\'s unique market position, its effectiveness, and the significant market need it addresses. The entrepreneurs also highlighted their sales success and customer loyalty.\"\\n  },\\n  \"initial_offer\": {\\n    \"amount\": \"$100,000\",\\n    \"equity\": \"10%\"\\n  }\\n}', tool_calls=[]))], prompt=[], usage=UsageData(prompt_tokens=1284, completion_tokens=306, total_tokens=1590))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a fixed set of agents:\n",
    "agents = select_models()\n",
    "\n",
    "pitches = {}\n",
    "for name, fact in facts_store:\n",
    "    pitch = generate_pitch(\n",
    "        fact, \n",
    "        num_agents=NUM_AGENTS, \n",
    "        reference_models=reference_models\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    pitches[name] = pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the dictionary as a JSON object\n",
    "with open('basic_multiagent_pitches.json', 'w') as f:\n",
    "    json.dumps(pitches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network based collaboration generation\n",
    "https://arxiv.org/pdf/2502.11098v1\n",
    "> Prompt --> Supervisor --> Generate --> Evaluate --> Repeat --> Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor_prompt = f\"\"\"\n",
    "You are a pitch editor. You will be given a pitch. Evaluate its strength. \n",
    "Give constructive feedback on how to improve the pitch a for shark tank pitch.\n",
    "Ensure your response is well-structured, coherent, and adheres to the highest standards of accuracy and reliability.\n",
    "Here is the pitch:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feedback_pitch(facts, num_agents=NUM_AGENTS, reference_models=reference_models, loops=3):\n",
    "    \"\"\"Run the main loop of the MOA process.\"\"\"\n",
    "    initial_pitch, feedback = None, None\n",
    "    for l in tqdm(range(loops)):\n",
    "        prompt = generate_user_prompt(facts)\n",
    "        if initial_pitch:\n",
    "            prompt += f\"\"\"\n",
    "            Here was your previous attempt: {initial_pitch}. Improve upon it.\n",
    "            \"\"\"\n",
    "        \n",
    "        if feedback:\n",
    "            prompt += f\"\"\"\n",
    "            This is the feedback of your previous attempt: {feedback}\n",
    "            \"\"\"\n",
    "        assignments = eval(run_llm(\n",
    "            client=client,\n",
    "            model=aggregator_model,\n",
    "            system_prompt=taskmaster_system_prompt,\n",
    "            user_prompt=prompt\n",
    "        ))\n",
    "        assignments_list = list(assignments.values())\n",
    "\n",
    "        results = [\n",
    "            run_llm(\n",
    "                client=client,\n",
    "                model=reference_models[i],\n",
    "                system_prompt=assignments_list[i][0]['content'],\n",
    "                user_prompt=assignments_list[i][1]['content']\n",
    "            ) for i in range(num_agents)\n",
    "        ]\n",
    "\n",
    "        final_pitch = run_llm(\n",
    "            client=client,\n",
    "            model=aggregator_model,\n",
    "            system_prompt=aggregator_system_prompt,\n",
    "            user_prompt=aggregate_results(results, prompt)\n",
    "        )\n",
    "\n",
    "        if l < loops-1:\n",
    "            evaluation = run_llm(\n",
    "                client=client,\n",
    "                model=evaluator_model,\n",
    "                system_prompt=editor_prompt,\n",
    "                user_prompt=final_pitch,\n",
    "                temperature=0.7\n",
    "            )\n",
    "\n",
    "            initial_pitch = final_pitch\n",
    "            feedback = evaluation\n",
    "    return final_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:15<00:00, 25.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\n",
      "  \"pitch\": {\n",
      "    \"delivery\": \"Welcome to GarmaGuard, a revolutionary fabric cleanser designed for busy lifestyles. Our product uses natural propellants to eliminate odor, freshen fabric, and control dirt and grime, all while killing 99% of germs and odor-causing bacteria. With a strong sales performance of $476,000 over 1.5 years, a projected sales target of $500,000 this year, a 20% profit margin, and 14,000 loyal customers, we are poised to revolutionize the fabric care industry. Our unique selling point is our on-the-go convenience, eco-friendliness, and effectiveness in eliminating odors and bacteria. To achieve these impressive results, we have implemented a comprehensive marketing and sales strategy, including digital marketing, content marketing, influencer marketing, paid advertising, event marketing, account-based sales, solution selling, consultative selling, referral and word-of-mouth marketing, data-driven sales, customer relationship management, sales enablement, pricing and discount strategies, partnerships and collaborations, and continuous improvement.\",\n",
      "    \"sentiment\": \"The pitch is delivered with enthusiasm and a clear passion for solving a real-world problem. The entrepreneurs, Pete and Bianca, effectively communicate the necessity and benefits of GarmaGuard, engaging the audience with a compelling narrative and demonstrating the product's effectiveness.\",\n",
      "    \"story\": \"GarmaGuard was born out of a need identified by Bianca, a nurse, for a product to clean clothes exposed to germs and bacteria throughout the day. The product's unique market position, effectiveness, and significant market need are highlighted, with a focus on its natural ingredients, convenience, and eco-friendliness.\",\n",
      "    \"key_aspects\": \"The pitch focuses on GarmaGuard's unique market position, its effectiveness, the large market need it addresses, its sales success, customer loyalty, and the various marketing and sales strategies used to achieve these results. A competitive analysis is provided to demonstrate GarmaGuard's unique strengths and potential for growth.\"\n",
      "  },\n",
      "  \"initial_offer\": {\n",
      "    \"amount\": \"$100,000\",\n",
      "    \"equity\": \"10%\",\n",
      "    \"use_of_funds\": {\n",
      "      \"product_development\": \"A portion of the investment will be allocated to research and development of new product lines that cater to the evolving needs and preferences of the target market.\",\n",
      "      \"marketing_and_advertising\": \"The investment will boost marketing efforts by funding digital advertising, social media promotions, and targeted campaigns to increase brand awareness and attract new customers.\",\n",
      "      \"inventory_and_supply_chain_management\": \"The funds will ensure a sufficient inventory of raw materials and finished products, ensuring timely delivery to customers and minimizing production delays.\",\n",
      "      \"hiring_and_training\": \"The investment will be used to hire additional staff members and invest in training programs to equip the team with the necessary skills and knowledge to excel in their roles.\",\n",
      "      \"technology_and_equipment_upgrades\": \"The funds will support upgrades to technology infrastructure and the purchase of new equipment to streamline operations, improve efficiency, and reduce costs in the long run.\",\n",
      "      \"business_operations\": \"The investment will cover various operational expenses, such as rent, utilities, and insurance, ensuring the stability and sustainability of the business as it grows.\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a fixed set of agents:\n",
    "agents = select_models()\n",
    "\n",
    "pitches = {}\n",
    "# for name, fact in facts_store:\n",
    "sample = list(facts_store.keys())[0]\n",
    "name, fact = sample, facts_store[sample]\n",
    "pitch = generate_feedback_pitch(\n",
    "    fact, \n",
    "    num_agents=NUM_AGENTS, \n",
    "    reference_models=reference_models\n",
    ")\n",
    "print(pitch)\n",
    "\n",
    "pitches[name] = pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sharktank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
