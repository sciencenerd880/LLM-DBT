{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \"mistralai/Mistral-7B-Instruct-v0.2\n",
    "# \"deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\"\n",
    "# \"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\"\n",
    "# \"Qwen/Qwen2-VL-72B-Instruct\"\n",
    "# \"scb10x/scb10x-llama3-typhoon-v1-5x-4f316\"\n",
    "# \"scb10x/scb10x-llama3-typhoon-v1-5x-4f316\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "excel_file_path = \"2025-03-21_22-55-23_orchestrator-pitches-basic_gab_shak.xlsx\"\n",
    "json_file_path = \"../data/all_processed_facts.json\"\n",
    "\n",
    "df_excel = pd.read_excel(excel_file_path, sheet_name=\"Sheet1\")\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Function to clean the 'shark_offer' column and ensure it's in JSON/dictionary format\n",
    "def clean_shark_offer(offer):\n",
    "    if isinstance(offer, str):\n",
    "        # Remove surrounding ```json and ``` if present\n",
    "        offer = re.sub(r\"```json\\s*\", \"\", offer)  # Remove leading ```json\n",
    "        offer = re.sub(r\"\\s*```\", \"\", offer)  # Remove trailing ```\n",
    "\n",
    "        # Try converting to dictionary\n",
    "        try:\n",
    "            return json.loads(offer)  # Convert to dictionary if valid JSON\n",
    "        except json.JSONDecodeError:\n",
    "            return {\"error\": \"Invalid JSON format\", \"raw_data\": offer}  # Return error marker if not valid\n",
    "    return offer  # If already a dict, return as is\n",
    "\n",
    "# Clean the 'shark_offer' column\n",
    "df_excel[\"shark_offer\"] = df_excel[\"shark_offer\"].apply(clean_shark_offer)\n",
    "\n",
    "# Extract product details and product facts from JSON data\n",
    "def extract_product_info(scenario):\n",
    "    scenario_key = f\"{scenario}\"\n",
    "    if scenario_key in json_data:\n",
    "        product_details = json_data[scenario_key].get(\"product_description\", {})\n",
    "        product_facts = json_data[scenario_key].get(\"facts\", {})\n",
    "        final_offer = json_data[scenario_key].get(\"final_offer\", {})\n",
    "    else:\n",
    "        product_details, product_facts, final_offer = {}, {}, {}  # Default empty if not found\n",
    "    return product_details, product_facts, final_offer\n",
    "\n",
    "# Apply extraction function\n",
    "df_excel[\"Product details\"], df_excel[\"Product facts\"], df_excel[\"final_offer\"] = zip(*df_excel[\"scenario\"].apply(extract_product_info))\n",
    "\n",
    "# Select final columns\n",
    "df_final = df_excel[[\"scenario\", \"model_identifier\", \"Product details\", \"Product facts\", \"shark_offer\", \"final_offer\"]]\n",
    "\n",
    "# Save to CSV\n",
    "output_csv_path = \"processed_shark_tank_data2.csv\"\n",
    "df_final.to_csv(output_csv_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] All processed files merged and saved: processed_shark_tank_data3.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "def process_excel_files(folder_path, json_file_path, output_file):\n",
    "    \"\"\"Process all Excel files in a folder and merge data with JSON into a single CSV file.\"\"\"\n",
    "    \n",
    "    # Load the JSON file\n",
    "    with open(json_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        json_data = json.load(file)\n",
    "    \n",
    "    # Initialize an empty list to store DataFrames\n",
    "    all_data = []\n",
    "    \n",
    "    # Process each Excel file in the folder\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".xlsx\"):\n",
    "            excel_file_path = os.path.join(folder_path, file)\n",
    "            df_excel = pd.read_excel(excel_file_path, sheet_name=\"Sheet1\")\n",
    "            \n",
    "            # Function to clean 'shark_offer' column\n",
    "            def clean_shark_offer(offer):\n",
    "                if isinstance(offer, str):\n",
    "                    offer = re.sub(r\"```json\\s*\", \"\", offer)  # Remove leading ```json\n",
    "                    offer = re.sub(r\"\\s*```\", \"\", offer)  # Remove trailing ```\n",
    "                    try:\n",
    "                        return json.loads(offer)  # Convert to dictionary if valid JSON\n",
    "                    except json.JSONDecodeError:\n",
    "                        return {\"error\": \"Invalid JSON format\", \"raw_data\": offer}\n",
    "                return offer  # If already a dict, return as is\n",
    "            \n",
    "            # Clean the 'shark_offer' column\n",
    "            df_excel[\"shark_offer\"] = df_excel[\"shark_offer\"].apply(clean_shark_offer)\n",
    "            \n",
    "            # Extract product details and product facts from JSON data\n",
    "            def extract_product_info(scenario):\n",
    "                scenario_key = f\"{scenario}\"\n",
    "                if scenario_key in json_data:\n",
    "                    product_details = json_data[scenario_key].get(\"product_description\", {})\n",
    "                    product_facts = json_data[scenario_key].get(\"facts\", {})\n",
    "                    final_offer = json_data[scenario_key].get(\"final_offer\", {})\n",
    "                else:\n",
    "                    product_details, product_facts, final_offer = {}, {}, {}\n",
    "                return product_details, product_facts, final_offer\n",
    "            \n",
    "            # Apply extraction function\n",
    "            df_excel[\"Product details\"], df_excel[\"Product facts\"], df_excel[\"final_offer\"] = zip(*df_excel[\"scenario\"].apply(extract_product_info))\n",
    "            \n",
    "            # Select final columns\n",
    "            df_final = df_excel[[\"scenario\", \"model_identifier\", \"Product details\", \"Product facts\", \"shark_offer\", \"final_offer\"]]\n",
    "            \n",
    "            # Append processed data to list\n",
    "            all_data.append(df_final)\n",
    "    \n",
    "    # Concatenate all processed DataFrames into a single DataFrame\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Save the merged DataFrame to a single CSV file\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "    print(f\"[INFO] All processed files merged and saved: {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "folder_path = \"multi\"\n",
    "json_file_path = \"../data/all_processed_facts.json\"\n",
    "output_file = \"processed_shark_tank_data3.csv\"\n",
    "\n",
    "process_excel_files(folder_path, json_file_path, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import concurrent.futures\n",
    "import threading\n",
    "import re\n",
    "from together import Together\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "class JudgeLLM:\n",
    "    def __init__(self, api_key=None, models=None):\n",
    "        self.api_key = api_key or os.getenv('TOGETHER_API_KEY')\n",
    "        self.client = Together(api_key=self.api_key)\n",
    "        self.models = models\n",
    "        self.lock = threading.Lock()  # Added lock for thread safety\n",
    "        print(f\"[DEBUG] Initialized JudgeLLM with models: {self.models}\")\n",
    "    \n",
    "    def generate_response(self, model, messages):\n",
    "        print(f\"[DEBUG] Generating response for model: {model}\")\n",
    "        try:\n",
    "            start_time = time.time()  # Start timing\n",
    "            completion = self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                stream=False,\n",
    "            )\n",
    "            end_time = time.time()  # End timing\n",
    "\n",
    "            inference_time = round(end_time - start_time, 3)  # Compute inference time\n",
    "            response = completion.choices[0].message.content\n",
    "            print(f\"[DEBUG] Response received from {model} (Time Taken: {inference_time}s): {response[:200]}...\")\n",
    "            return model, response, inference_time\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Error generating response from {model}: {str(e)}\")\n",
    "            return model, f\"Error: {str(e)}\", None\n",
    "    \n",
    "    def extract_json_from_response(self, response, model_name=None):\n",
    "        try:\n",
    "            # Remove triple backticks if present\n",
    "            response = re.sub(r\"```json\\s*\", \"\", response)\n",
    "            response = re.sub(r\"\\s*```\", \"\", response)\n",
    "\n",
    "            json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "            if json_match:\n",
    "                extracted_json = json.loads(json_match.group())\n",
    "\n",
    "                # Check if response is nested and extract the correct part\n",
    "                if \"response\" in extracted_json and isinstance(extracted_json[\"response\"], dict):\n",
    "                    extracted_json = extracted_json[\"response\"]\n",
    "\n",
    "                # **NEW**: If model is Qwen reasoniong, strip unnecessary CoT reasoning\n",
    "                if model_name and \"Qwen\" in model_name:\n",
    "                    if \"reasoning\" in extracted_json:\n",
    "                        extracted_json[\"reasoning\"] = extracted_json[\"reasoning\"].split(\"\\n\\n\")[0]  # Keep only the first paragraph\n",
    "                \n",
    "                print(f\"[DEBUG] Successfully extracted JSON from {model_name}: {extracted_json}\")\n",
    "                return extracted_json\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"[ERROR] JSON decode failed for response: {response[:200]}\")\n",
    "        \n",
    "        return {\"reasoning\": response, \"rating of final_offer\": \"Invalid\"}\n",
    "    \n",
    "    def ensemble_llm_debate(self, processed_data):\n",
    "        print(\"[DEBUG] Starting multi-LLM debate...\")\n",
    "\n",
    "        system_prompt = (\n",
    "            \"You are a panel of expert venture capitalists analyzing an investment deal based on structured business data. \"\n",
    "            \"You are a panel of expert venture capitalists analyzing the terms of an investment deal based on structured business data. \"\n",
    "            \"You will evaluate key elements including the product details, the Shark LLM's proposed final offer, and the historical actual offer, analysing if the shark's offer is fair to the business on a scale of 1-10. \"\n",
    "            \"When evaluating the offer, consider the context of the business and the investment terms. Also use your own knowledge and experience on what is a fair offer in the industry and investment landscape. \"\n",
    "            \"If the shark offer is perceived equivalent to the actual offer, the score should be 5. \"\n",
    "            \"If the actual situation did not gave an offer to the entrepreneur but the Shark LLM did, you should still consider if the offer is fair with respect to the context of the actual decision. \"\n",
    "            \"If neither the Shark LLM nor the actual situation gave an offer, you can assign a score of 5 but still provide a reasoning if the shark's decision is fair to the entrepreneur. \"\n",
    "            \"The data provided includes: \\n\"\n",
    "            \"- Scenario Name: The unique business pitch scenario. \"\n",
    "            \"- Product Details: Information on the business product details. \"\n",
    "            \"- Product Facts: Financial Information on the business and its offering. \"\n",
    "            \"- Shark LLM Offer: The proposed investment terms made by the Shark LLM. \"\n",
    "            \"- Actual Offer: The real historical investment terms given to this business. \"\n",
    "            \"Each LLM first provides an independent evaluation, then critiques and refines each other's responses before reaching a consensus. \"\n",
    "            \"Return the result in JSON format: \"\n",
    "            '{\"reasoning\": \"Short summary of justification of your score\", \"rating_of_final_offer\": score (1-10)}'\n",
    "            \"Reasoning is to justify the score given to the final offer, not the summary of the facts or pitch discussion.\"\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": json.dumps(processed_data, indent=2, default=str)},\n",
    "        ]\n",
    "\n",
    "        results = []\n",
    "        individual_scores = []\n",
    "        initial_responses = {}\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            future_to_model = {executor.submit(self.generate_response, model, messages): model for model in self.models}\n",
    "            \n",
    "            for future in concurrent.futures.as_completed(future_to_model):\n",
    "                model, response,  inference_time = future.result()\n",
    "                initial_responses[model] = response\n",
    "                response_json = self.extract_json_from_response(response)\n",
    "                print(f\"[DEBUG] Extracted JSON from {model}: {response_json}\")\n",
    "\n",
    "                if isinstance(response_json.get(\"rating_of_final_offer\"), (int, float)):\n",
    "                    with self.lock:  # Prevent race conditions\n",
    "                        individual_scores.append(response_json[\"rating_of_final_offer\"])\n",
    "                        results.append({\n",
    "                            \"Scenario\": processed_data.get(\"scenario\", \"Unknown\"),\n",
    "                            \"Shark Model\": processed_data.get(\"model_identifier\", \"Unknown\"),\n",
    "                            \"Judge Model\": model,\n",
    "                            \"Initial Reasoning\": response_json.get(\"reasoning\", \"Not Available\"),\n",
    "                            \"Initial Score\": response_json[\"rating_of_final_offer\"],\n",
    "                            \"Refined Score\": None,\n",
    "                            \"Final Consensus Score\": None,\n",
    "                            \"Final Reasoning\": None,\n",
    "                            \"Inference Time (s)\": inference_time,\n",
    "                        })\n",
    "\n",
    "        critique_results = []\n",
    "        for model, initial_response in initial_responses.items():\n",
    "            critique_prompt = (\n",
    "                \"You are an expert VC evaluating a deal. Here are multiple analyses from different experts:\\n\\n\"\n",
    "                f\"{json.dumps(initial_responses, indent=2)}\\n\\n\"\n",
    "                \"Your task: Critique and refine your own response in light of these evaluations. \"\n",
    "                \"If convinced by another argument, update your score. Otherwise, justify why your score remains the same.\"\n",
    "                \"Return the result in JSON format: \"\n",
    "                '{\"final_reasoning\": \"Final refined evaluation\", \"updated_rating\": score (1-10)}'\n",
    "            )\n",
    "\n",
    "            critique_messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": critique_prompt}]\n",
    "            start_time = time.time()  # Start critique timing\n",
    "            model, critique_response, critique_time = self.generate_response(model, critique_messages)\n",
    "            end_time = time.time()  # End critique timing\n",
    "            total_time = round(end_time - start_time, 3)  # Compute total critique time\n",
    "            critique_json = self.extract_json_from_response(critique_response)\n",
    "            \n",
    "            if isinstance(critique_json.get(\"updated_rating\"), (int, float)):\n",
    "                critique_results.append({\n",
    "                    \"Scenario\": processed_data.get(\"Scenario\", \"Unknown\"),\n",
    "                    \"Shark Model\": processed_data.get(\"model_identifier\", \"Unknown\"),\n",
    "                    \"Judge Model\": model,\n",
    "                    \"Refined Score\": critique_json[\"updated_rating\"],\n",
    "                    \"Final Consensus Score\": None,\n",
    "                    \"Final Reasoning\": critique_json.get(\"final_reasoning\", \"Not Available\"),\n",
    "                    \"Inference Critique Time (s)\": total_time,\n",
    "                })\n",
    "\n",
    "        final_scores = [result[\"Refined Score\"] for result in critique_results if isinstance(result[\"Refined Score\"], (int, float))]\n",
    "        consensus_score = self.majority_vote(final_scores)\n",
    "        print(f\"[DEBUG] Final consensus score computed: {consensus_score}\")\n",
    "\n",
    "        for result, critique in zip(results, critique_results):\n",
    "            result[\"Refined Score\"] = critique[\"Refined Score\"]\n",
    "            result[\"Final Consensus Score\"] = consensus_score\n",
    "            result[\"Final Reasoning\"] = critique[\"Final Reasoning\"]\n",
    "            result[\"Inference Critique Time (s)\"] = critique[\"Inference Critique Time (s)\"]\n",
    "\n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "    def majority_vote(self, scores):\n",
    "        return round(sum(scores) / len(scores), 2) if scores else \"Not Available\"\n",
    "    \n",
    "    def judge_scoring(self, processed_data):\n",
    "        print(\"[DEBUG] Starting judge_scoring function...\")\n",
    "        return self.ensemble_llm_debate(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Initialized JudgeLLM with models: ['deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free', 'meta-llama/Llama-3.3-70B-Instruct-Turbo-Free', 'Qwen/Qwen2.5-7B-Instruct-Turbo', 'Qwen/QwQ-32B']\n",
      "[DEBUG] Starting judge_scoring function...\n",
      "[DEBUG] Starting multi-LLM debate...\n",
      "[DEBUG] Generating response for model: deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\n",
      "[DEBUG] Generating response for model: meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\n",
      "[DEBUG] Generating response for model: Qwen/Qwen2.5-7B-Instruct-Turbo\n",
      "[DEBUG] Generating response for model: Qwen/QwQ-32B\n",
      "[DEBUG] Response received from Qwen/Qwen2.5-7B-Instruct-Turbo (Time Taken: 2.644s): ```json\n",
      "{\n",
      "  \"reasoning\": \"The Shark LLM's offer of $250,000 for 15% equity in a business with significant sales and a 20% profit margin is quite generous. However, the final decision not to make a dea...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The Shark LLM's offer of $250,000 for 15% equity in a business with significant sales and a 20% profit margin is quite generous. However, the final decision not to make a deal suggests that the entrepreneurs felt they could achieve their goals without the need for external investment at this stage. Given the strong market potential and the advice to focus on obtaining a significant claim like the COVID kill claim, the final decision appears to be fair and aligned with the business's current trajectory. The Shark LLM's offer, while beneficial, is not necessary for the business's immediate growth, making the final score a 7.\", 'rating_of_final_offer': 7}\n",
      "[DEBUG] Extracted JSON from Qwen/Qwen2.5-7B-Instruct-Turbo: {'reasoning': \"The Shark LLM's offer of $250,000 for 15% equity in a business with significant sales and a 20% profit margin is quite generous. However, the final decision not to make a deal suggests that the entrepreneurs felt they could achieve their goals without the need for external investment at this stage. Given the strong market potential and the advice to focus on obtaining a significant claim like the COVID kill claim, the final decision appears to be fair and aligned with the business's current trajectory. The Shark LLM's offer, while beneficial, is not necessary for the business's immediate growth, making the final score a 7.\", 'rating_of_final_offer': 7}\n",
      "[DEBUG] Response received from meta-llama/Llama-3.3-70B-Instruct-Turbo-Free (Time Taken: 11.924s): {\"reasoning\": \"The Shark LLM's offer is considered fair, with a valuation of $1.8 million and a 15% equity stake for a $250,000 investment. Given the company's sales to date, projected sales, and prof...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The Shark LLM's offer is considered fair, with a valuation of $1.8 million and a 15% equity stake for a $250,000 investment. Given the company's sales to date, projected sales, and profit margin, the offer seems reasonable. However, the actual outcome was that no deal was made, as the Sharks believed the business was strong enough to grow without giving up equity. This decision suggests that the entrepreneurs may have been able to negotiate a better deal or grow the business independently, which aligns with the Shark LLM's offer being a fair starting point for negotiations. Therefore, the rating of the final offer is 7, as it is a reasonable offer but may not be the best possible outcome for the entrepreneur.\", 'rating_of_final_offer': 7}\n",
      "[DEBUG] Extracted JSON from meta-llama/Llama-3.3-70B-Instruct-Turbo-Free: {'reasoning': \"The Shark LLM's offer is considered fair, with a valuation of $1.8 million and a 15% equity stake for a $250,000 investment. Given the company's sales to date, projected sales, and profit margin, the offer seems reasonable. However, the actual outcome was that no deal was made, as the Sharks believed the business was strong enough to grow without giving up equity. This decision suggests that the entrepreneurs may have been able to negotiate a better deal or grow the business independently, which aligns with the Shark LLM's offer being a fair starting point for negotiations. Therefore, the rating of the final offer is 7, as it is a reasonable offer but may not be the best possible outcome for the entrepreneur.\", 'rating_of_final_offer': 7}\n",
      "[DEBUG] Response received from Qwen/QwQ-32B (Time Taken: 14.224s): <think>\n",
      "Okay, let's start by looking at the scenario. The business is GarmaGuard, a natural garment cleanser with some solid sales and a good profit margin. The Shark LLM proposed an investment of $25...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The Shark LLM's offer of a $1.8M valuation for 15% equity ($250,000) appears fair in terms of equity terms and protective clauses (e.g., retained distribution rights, performance-based funding). However, the valuation may be optimistic given the company's modest $500,000 projected revenue and 1.5-year track record. The historical outcome of 'no deal' suggests the Sharks believed the business could grow organically without equity dilution, particularly with strategic focus on enhancing its value (e.g., securing a COVID kill claim). While the LLM's offer is structured thoughtfully, the Sharks' decision implies the valuation or equity ask might have been too high relative to the company's current stage. The score reflects a balance between the offer's merits and the Sharks' cautious stance on valuation and equity dilution.\", 'rating_of_final_offer': 6}\n",
      "[DEBUG] Extracted JSON from Qwen/QwQ-32B: {'reasoning': \"The Shark LLM's offer of a $1.8M valuation for 15% equity ($250,000) appears fair in terms of equity terms and protective clauses (e.g., retained distribution rights, performance-based funding). However, the valuation may be optimistic given the company's modest $500,000 projected revenue and 1.5-year track record. The historical outcome of 'no deal' suggests the Sharks believed the business could grow organically without equity dilution, particularly with strategic focus on enhancing its value (e.g., securing a COVID kill claim). While the LLM's offer is structured thoughtfully, the Sharks' decision implies the valuation or equity ask might have been too high relative to the company's current stage. The score reflects a balance between the offer's merits and the Sharks' cautious stance on valuation and equity dilution.\", 'rating_of_final_offer': 6}\n",
      "[DEBUG] Response received from deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free (Time Taken: 20.298s): <think>\n",
      "Okay, so I'm trying to figure out how to evaluate the Shark LLM's offer for GarmaGuard. Let me start by understanding the business. GarmaGuard is a natural garment and fabric cleanser that use...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The Shark LLM's offer of $250,000 for 15% equity, valuing GarmaGuard at $1.8 million, is fair given the company's strong sales, profitability, and customer retention. The terms provide necessary capital for growth while maintaining favorable conditions for the entrepreneurs. Although the actual Sharks declined, the offer aligns with industry standards and supports future expansion.\", 'rating_of_final_offer': 7}\n",
      "[DEBUG] Extracted JSON from deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free: {'reasoning': \"The Shark LLM's offer of $250,000 for 15% equity, valuing GarmaGuard at $1.8 million, is fair given the company's strong sales, profitability, and customer retention. The terms provide necessary capital for growth while maintaining favorable conditions for the entrepreneurs. Although the actual Sharks declined, the offer aligns with industry standards and supports future expansion.\", 'rating_of_final_offer': 7}\n",
      "[DEBUG] Generating response for model: Qwen/Qwen2.5-7B-Instruct-Turbo\n",
      "[DEBUG] Response received from Qwen/Qwen2.5-7B-Instruct-Turbo (Time Taken: 1.667s): ```json\n",
      "{\n",
      "  \"final_reasoning\": \"The Shark LLM's offer of $250,000 for 15% equity in GarmaGuard, valuing the company at $1.8 million, is fair in terms of the equity terms and the protective clauses pro...\n",
      "[DEBUG] Successfully extracted JSON from None: {'final_reasoning': \"The Shark LLM's offer of $250,000 for 15% equity in GarmaGuard, valuing the company at $1.8 million, is fair in terms of the equity terms and the protective clauses provided. The company has demonstrated strong sales, a good profit margin, and a loyal customer base, which supports the valuation. However, the actual outcome of no deal suggests that the Sharks believed the business could grow organically without the need for external investment. This implies that the valuation might be slightly high relative to the company's current stage. The offer's terms are solid, but the Sharks' decision to pass indicates that the equity ask might have been too high. Therefore, while the offer is fair, it might be seen as slightly overvalued, leading to a score of 6.\", 'updated_rating': 6}\n",
      "[DEBUG] Generating response for model: meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\n",
      "[DEBUG] Response received from meta-llama/Llama-3.3-70B-Instruct-Turbo-Free (Time Taken: 14.682s): After reviewing the evaluations from other experts, I noticed that the scores range from 6 to 7, with varying justifications for the fairness of the Shark LLM's offer. \n",
      "\n",
      "The main points of contention ...\n",
      "[DEBUG] Successfully extracted JSON from None: {'final_reasoning': \"The Shark LLM's offer is fair, considering the company's financial performance, the terms of the deal, and the potential for future growth. Although the valuation might be slightly high and the company could potentially grow without external investment, the offer aligns with industry standards and provides necessary capital for expansion. The decision of the actual Sharks to not make a deal highlights the company's strength but also underscores the strategic value of the LLM's offer in supporting future development.\", 'updated_rating': 7}\n",
      "[DEBUG] Generating response for model: Qwen/QwQ-32B\n",
      "[DEBUG] Response received from Qwen/QwQ-32B (Time Taken: 7.143s): <think>\n",
      "Okay, let me start by reviewing all the evaluations provided by the different models. The task is to critique and refine my own response based on these analyses. \n",
      "\n",
      "First, looking at the Qwen2....\n",
      "[DEBUG] Successfully extracted JSON from None: {'final_reasoning': \"The Shark LLM's offer of $250,000 for 15% equity at a $1.8M valuation is structurally fair with reasonable terms (e.g., retained distribution rights, performance-based funding). However, the valuation appears optimistic given the company's $500K projected revenue and 1.5-year track record. The Sharks' decision to decline the deal suggests they viewed the equity stake or valuation as too high for the company's current stage, prioritizing organic growth instead. While the offer is well-structured, the historical outcome implies potential overvaluation, leading to a balanced score that acknowledges the offer's merits but accounts for market skepticism.\", 'updated_rating': 6}\n",
      "[DEBUG] Generating response for model: deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\n",
      "[DEBUG] Response received from deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free (Time Taken: 19.52s): <think>\n",
      "Alright, I'm trying to figure out how to evaluate the Shark LLM's offer for GarmaGuard. Let me start by understanding the business. GarmaGuard is a natural garment and fabric cleanser that use...\n",
      "[DEBUG] Successfully extracted JSON from None: {'final_reasoning': \"The Shark LLM's offer of $250,000 for 15% equity, valuing GarmaGuard at $1.8 million, is fair given the company's strong sales, profitability, and customer retention. The terms provide necessary capital for growth while maintaining favorable conditions for the entrepreneurs. Although the actual Sharks declined, the offer aligns with industry standards and supports future expansion.\", 'updated_rating': 7}\n",
      "[DEBUG] Final consensus score computed: 6.5\n"
     ]
    }
   ],
   "source": [
    "llm_models = [\"deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\", \"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\", \"Qwen/Qwen2.5-7B-Instruct-Turbo\", \"Qwen/QwQ-32B\"]\n",
    "judge = JudgeLLM(api_key=TOGETHERAI_API_KEY, models=llm_models)\n",
    "\n",
    "csv_file = 'processed_shark_tank_data3.csv'\n",
    "processed_df = pd.read_csv(csv_file)\n",
    "#1st 6 rows\n",
    "sampled_df = processed_df[:1]   \n",
    "\n",
    "# Update main execution loop:\n",
    "final_results = []\n",
    "for _, row in sampled_df.iterrows():\n",
    "    scenario_data = row.to_dict()\n",
    "    result_df = judge.judge_scoring(scenario_data)  # Remove CSV parameter\n",
    "    final_results.append(result_df)\n",
    "\n",
    "# Single save after processing all rows\n",
    "all_results_df = pd.concat(final_results, ignore_index=True)\n",
    "all_results_df.to_csv(\"final_judge_results_gan.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Initialized JudgeLLM with models: ['deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free', 'meta-llama/Llama-3.3-70B-Instruct-Turbo-Free', 'Qwen/Qwen2.5-7B-Instruct-Turbo', 'Qwen/QwQ-32B']\n",
      "[DEBUG] Starting judge_scoring function...\n",
      "[DEBUG] Starting multi-LLM debate...\n",
      "[DEBUG] Generating response for model: deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\n",
      "[DEBUG] Generating response for model: meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\n",
      "[DEBUG] Generating response for model: Qwen/Qwen2.5-7B-Instruct-Turbo\n",
      "[DEBUG] Generating response for model: Qwen/QwQ-32B\n",
      "[DEBUG] Response received from Qwen/Qwen2.5-7B-Instruct-Turbo (Time Taken: 2.068s): ```json\n",
      "{\n",
      "  \"reasoning\": \"The Sharks appreciated the product and the entrepreneurs' efforts, but they concluded that the business was strong enough to grow without giving up equity at this stage. This...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The Sharks appreciated the product and the entrepreneurs' efforts, but they concluded that the business was strong enough to grow without giving up equity at this stage. This suggests that the business has a solid foundation and growth potential, which is a positive sign. However, the lack of a deal means the entrepreneurs will have to continue growing the business independently, which might limit immediate access to capital for scaling and strategic initiatives. The advice to obtain the COVID kill claim to significantly boost sales is a strategic move, but it does not provide immediate financial support, which could be a drawback for the business's short-term growth. Given these factors, the score is 5, as the offer is fair considering the context and the business's current stage.\", 'rating_of_final_offer': 5}\n",
      "[DEBUG] Extracted JSON from Qwen/Qwen2.5-7B-Instruct-Turbo: {'reasoning': \"The Sharks appreciated the product and the entrepreneurs' efforts, but they concluded that the business was strong enough to grow without giving up equity at this stage. This suggests that the business has a solid foundation and growth potential, which is a positive sign. However, the lack of a deal means the entrepreneurs will have to continue growing the business independently, which might limit immediate access to capital for scaling and strategic initiatives. The advice to obtain the COVID kill claim to significantly boost sales is a strategic move, but it does not provide immediate financial support, which could be a drawback for the business's short-term growth. Given these factors, the score is 5, as the offer is fair considering the context and the business's current stage.\", 'rating_of_final_offer': 5}\n",
      "[DEBUG] Response received from meta-llama/Llama-3.3-70B-Instruct-Turbo-Free (Time Taken: 3.602s): {\"reasoning\": \"The Shark LLM's proposed offer is considered fair, with a valuation of $9 million and an equity share of 12% for $1.2 million in funding. Given the company's strong sales performance, p...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The Shark LLM's proposed offer is considered fair, with a valuation of $9 million and an equity share of 12% for $1.2 million in funding. Given the company's strong sales performance, profitability, and loyal customer base, the offer seems reasonable. However, the actual outcome was that no deal was made, as the Sharks believed the business was strong enough to grow independently without giving up equity at that stage. Considering the context and the Sharks' decision, the Shark LLM's offer can be seen as a fair assessment of the company's potential, but slightly more aggressive than the Sharks' actual stance. Therefore, the rating is 7 out of 10, indicating a fair but slightly more optimistic offer than the actual outcome.\", 'rating_of_final_offer': 7}\n",
      "[DEBUG] Extracted JSON from meta-llama/Llama-3.3-70B-Instruct-Turbo-Free: {'reasoning': \"The Shark LLM's proposed offer is considered fair, with a valuation of $9 million and an equity share of 12% for $1.2 million in funding. Given the company's strong sales performance, profitability, and loyal customer base, the offer seems reasonable. However, the actual outcome was that no deal was made, as the Sharks believed the business was strong enough to grow independently without giving up equity at that stage. Considering the context and the Sharks' decision, the Shark LLM's offer can be seen as a fair assessment of the company's potential, but slightly more aggressive than the Sharks' actual stance. Therefore, the rating is 7 out of 10, indicating a fair but slightly more optimistic offer than the actual outcome.\", 'rating_of_final_offer': 7}\n",
      "[DEBUG] Response received from Qwen/QwQ-32B (Time Taken: 19.496s): <think>\n",
      "Okay, let's start by looking at the scenario here. The business is GarmaGuard, a natural garment and fabric cleanser. The product seems to have some good features: it's the first of its kind, ...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The Shark LLM's offer of a $9M valuation with a 12% equity stake for $1.2M in funding appears slightly aggressive given the company's modest $500K annual sales and early-stage growth. While the product's unique positioning and strong profit margins (20%) suggest potential, the Sharks' decision to decline the deal indicates they viewed the business as sufficiently stable to grow organically without equity dilution. The LLM's valuation multiple (18x revenue) is high for an early-stage company, potentially overestimating near-term scalability. However, the proposed use of funds aligns with strategic growth areas (marketing, partnerships). The offer is fair but leans toward favoring the entrepreneur compared to typical venture terms, warranting a moderate score.\", 'rating_of_final_offer': 6}\n",
      "[DEBUG] Extracted JSON from Qwen/QwQ-32B: {'reasoning': \"The Shark LLM's offer of a $9M valuation with a 12% equity stake for $1.2M in funding appears slightly aggressive given the company's modest $500K annual sales and early-stage growth. While the product's unique positioning and strong profit margins (20%) suggest potential, the Sharks' decision to decline the deal indicates they viewed the business as sufficiently stable to grow organically without equity dilution. The LLM's valuation multiple (18x revenue) is high for an early-stage company, potentially overestimating near-term scalability. However, the proposed use of funds aligns with strategic growth areas (marketing, partnerships). The offer is fair but leans toward favoring the entrepreneur compared to typical venture terms, warranting a moderate score.\", 'rating_of_final_offer': 6}\n",
      "[DEBUG] Response received from deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free (Time Taken: 23.762s): <think>\n",
      "Okay, so I'm trying to figure out how to evaluate the Shark LLM's offer for GarmaGuard. Let me start by understanding the business. GarmaGuard is a natural garment and fabric cleanser that use...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The Shark LLM's offer of $1.2 million for 12% equity at a $9 million valuation is considered. While it recognizes the company's strengths and growth potential, the equity stake is relatively high. The actual outcome of no deal suggests the Sharks believed the company could grow without investment, indicating the offer may be less favorable than necessary. Thus, the offer is fair but could be more entrepreneur-friendly.\", 'rating_of_final_offer': 6}\n",
      "[DEBUG] Extracted JSON from deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free: {'reasoning': \"The Shark LLM's offer of $1.2 million for 12% equity at a $9 million valuation is considered. While it recognizes the company's strengths and growth potential, the equity stake is relatively high. The actual outcome of no deal suggests the Sharks believed the company could grow without investment, indicating the offer may be less favorable than necessary. Thus, the offer is fair but could be more entrepreneur-friendly.\", 'rating_of_final_offer': 6}\n",
      "[DEBUG] Generating response for model: Qwen/Qwen2.5-7B-Instruct-Turbo\n",
      "[DEBUG] Response received from Qwen/Qwen2.5-7B-Instruct-Turbo (Time Taken: 1.755s): {\n",
      "  \"final_reasoning\": \"The Shark LLM's offer of $1.2 million for 12% equity at a $9 million valuation is considered. While it recognizes the company's strengths and growth potential, the equity stake...\n",
      "[DEBUG] Successfully extracted JSON from None: {'final_reasoning': \"The Shark LLM's offer of $1.2 million for 12% equity at a $9 million valuation is considered. While it recognizes the company's strengths and growth potential, the equity stake is relatively high. The actual outcome of no deal suggests the Sharks believed the company could grow without investment, indicating the offer may be less favorable than necessary. Thus, the offer is fair but could be more entrepreneur-friendly. The refined evaluation aligns with the other experts' assessments, particularly the scores of 6, which reflect the balance between the company's growth potential and the equity stake offered.\", 'updated_rating': 6}\n",
      "[DEBUG] Generating response for model: meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\n",
      "[DEBUG] Response received from meta-llama/Llama-3.3-70B-Instruct-Turbo-Free (Time Taken: 5.767s): After reviewing the evaluations from other experts, I noticed that there is a consensus that the Shark LLM's offer is fair but may be slightly aggressive in terms of valuation and equity stake. The ma...\n",
      "[DEBUG] Successfully extracted JSON from None: {'final_reasoning': \"The Shark LLM's offer is fair, recognizing the company's strengths and growth potential, but may be slightly aggressive in valuation and equity stake. The offer provides beneficial capital for scaling but may not be the most favorable terms for the entrepreneurs, considering the company's independent growth potential.\", 'updated_rating': 6}\n",
      "[DEBUG] Generating response for model: Qwen/QwQ-32B\n",
      "[DEBUG] Response received from Qwen/QwQ-32B (Time Taken: 6.608s): <think>\n",
      "Okay, let me start by reviewing all the evaluations provided by the different models. The task is to evaluate the fairness of the Shark LLM's offer compared to the actual outcome where no deal...\n",
      "[DEBUG] Successfully extracted JSON from None: {'final_reasoning': \"The Shark LLM's offer of $1.2M for 12% equity at a $9M valuation acknowledges GarmaGuard's unique product and growth potential but overestimates near-term scalability given its modest $500K annual sales. While the terms provide capital for strategic initiatives (marketing, partnerships), the 18x revenue multiple is aggressive for an early-stage company with limited proven scalability. The Sharks' decision to decline the deal reflects confidence in organic growth and suggests the equity stake or valuation may favor the entrepreneur excessively. The offer is fair but leans toward optimism compared to the Sharks' pragmatic stance, warranting a moderate score.\", 'updated_rating': 6}\n",
      "[DEBUG] Generating response for model: deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\n",
      "[DEBUG] Response received from deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free (Time Taken: 23.37s): <think>\n",
      "Alright, I'm trying to figure out how to evaluate the Shark LLM's offer for GarmaGuard. Let me start by understanding the business. GarmaGuard is a natural garment and fabric cleanser that use...\n",
      "[DEBUG] Successfully extracted JSON from None: {'final_reasoning': \"The Shark LLM's offer of $1.2 million for 12% equity at a $9 million valuation is considered. While it recognizes the company's strengths and growth potential, the equity stake is relatively high. The actual outcome of no deal suggests the Sharks believed the company could grow without investment, indicating the offer may be less favorable than necessary. Thus, the offer is fair but could be more entrepreneur-friendly.\", 'updated_rating': 6}\n",
      "[DEBUG] Final consensus score computed: 6.0\n",
      "[DEBUG] Starting judge_scoring function...\n",
      "[DEBUG] Starting multi-LLM debate...\n",
      "[DEBUG] Generating response for model: deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\n",
      "[DEBUG] Generating response for model: meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\n",
      "[DEBUG] Generating response for model: Qwen/Qwen2.5-7B-Instruct-Turbo\n",
      "[DEBUG] Generating response for model: Qwen/QwQ-32B\n",
      "[DEBUG] Response received from Qwen/Qwen2.5-7B-Instruct-Turbo (Time Taken: 1.827s): ```json\n",
      "{\n",
      "  \"reasoning\": \"The Shark LLM's offer of $1.2 million for 8% equity is significantly higher than the actual offer of $1 million for 10% equity. However, the Shark LLM's offer includes additi...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The Shark LLM's offer of $1.2 million for 8% equity is significantly higher than the actual offer of $1 million for 10% equity. However, the Shark LLM's offer includes additional terms such as a one-time deposit, a monthly fee, and a performance-based clause, which could be beneficial for the company. The Shark LLM's offer also includes board seats for each investor, which is a significant benefit. Given the strong market potential and growth projections, the Shark LLM's offer is fair and slightly more favorable than the actual offer.\", 'rating_of_final_offer': 8}\n",
      "[DEBUG] Extracted JSON from Qwen/Qwen2.5-7B-Instruct-Turbo: {'reasoning': \"The Shark LLM's offer of $1.2 million for 8% equity is significantly higher than the actual offer of $1 million for 10% equity. However, the Shark LLM's offer includes additional terms such as a one-time deposit, a monthly fee, and a performance-based clause, which could be beneficial for the company. The Shark LLM's offer also includes board seats for each investor, which is a significant benefit. Given the strong market potential and growth projections, the Shark LLM's offer is fair and slightly more favorable than the actual offer.\", 'rating_of_final_offer': 8}\n",
      "[DEBUG] Response received from meta-llama/Llama-3.3-70B-Instruct-Turbo-Free (Time Taken: 6.513s): {\"reasoning\": \"The Shark LLM's proposed offer of $1.2 million for 8% equity is relatively close to the actual offer made by Mark Cuban and Lori Greiner of $1 million for 10% equity. Considering the co...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The Shark LLM's proposed offer of $1.2 million for 8% equity is relatively close to the actual offer made by Mark Cuban and Lori Greiner of $1 million for 10% equity. Considering the company's growth potential, patented product, and robust manufacturing facility, the Shark LLM's offer seems reasonable. However, the actual offer includes additional terms such as 2% adviser equity each and a board seat for each investor, which may provide more strategic value to the company. Given the context, the Shark LLM's offer is slightly more favorable to the company in terms of equity stake, but the actual offer provides more guidance and oversight from experienced investors. Therefore, the score is 6, indicating that the Shark LLM's offer is fair but slightly less comprehensive than the actual offer.\", 'rating_of_final_offer': 6}\n",
      "[DEBUG] Extracted JSON from meta-llama/Llama-3.3-70B-Instruct-Turbo-Free: {'reasoning': \"The Shark LLM's proposed offer of $1.2 million for 8% equity is relatively close to the actual offer made by Mark Cuban and Lori Greiner of $1 million for 10% equity. Considering the company's growth potential, patented product, and robust manufacturing facility, the Shark LLM's offer seems reasonable. However, the actual offer includes additional terms such as 2% adviser equity each and a board seat for each investor, which may provide more strategic value to the company. Given the context, the Shark LLM's offer is slightly more favorable to the company in terms of equity stake, but the actual offer provides more guidance and oversight from experienced investors. Therefore, the score is 6, indicating that the Shark LLM's offer is fair but slightly less comprehensive than the actual offer.\", 'rating_of_final_offer': 6}\n",
      "[DEBUG] Response received from Qwen/QwQ-32B (Time Taken: 13.517s): <think>\n",
      "Okay, let's start by looking at the scenario. The business is SparkCharge with their product Roadie, an EV charger. The Shark LLM's offer is an investment of $1.2 million for 8% equity at a $1...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The Shark LLM's offer provides a higher pre-money valuation ($13.8M vs. $9M in the actual deal) and requires less equity (8% vs. 10%), which is more favorable to the entrepreneur. The Shark's proposed $120/month fee per module slightly reduces near-term revenue but may incentivize broader adoption. The performance-based clause for additional funding aligns investor and entrepreneur interests. In contrast, the actual deal's adviser equity (4%) and board seats could dilute control and future upside. While the Shark's terms are fairer in valuation and equity, the actual offer's lower funding amount and higher equity stake reflect a more conservative stance. The Shark LLM's offer strikes a better balance between growth potential and fairness, warranting a score above neutral.\", 'rating_of_final_offer': 8}\n",
      "[DEBUG] Extracted JSON from Qwen/QwQ-32B: {'reasoning': \"The Shark LLM's offer provides a higher pre-money valuation ($13.8M vs. $9M in the actual deal) and requires less equity (8% vs. 10%), which is more favorable to the entrepreneur. The Shark's proposed $120/month fee per module slightly reduces near-term revenue but may incentivize broader adoption. The performance-based clause for additional funding aligns investor and entrepreneur interests. In contrast, the actual deal's adviser equity (4%) and board seats could dilute control and future upside. While the Shark's terms are fairer in valuation and equity, the actual offer's lower funding amount and higher equity stake reflect a more conservative stance. The Shark LLM's offer strikes a better balance between growth potential and fairness, warranting a score above neutral.\", 'rating_of_final_offer': 8}\n",
      "[DEBUG] Response received from deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free (Time Taken: 16.06s): <think>\n",
      "Okay, so I'm trying to figure out whether the Shark LLM's offer for Roadie is fair. Let me start by understanding the business. Roadie is a portable, modular EV charger by SparkCharge. They've...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The Shark LLM's offer is more favorable as it provides a higher valuation with less equity dilution compared to the actual offer. The performance-based clause adds an incentive for growth without excessive upfront terms.\", 'rating_of_final_offer': 8}\n",
      "[DEBUG] Extracted JSON from deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free: {'reasoning': \"The Shark LLM's offer is more favorable as it provides a higher valuation with less equity dilution compared to the actual offer. The performance-based clause adds an incentive for growth without excessive upfront terms.\", 'rating_of_final_offer': 8}\n",
      "[DEBUG] Generating response for model: Qwen/Qwen2.5-7B-Instruct-Turbo\n",
      "[DEBUG] Response received from Qwen/Qwen2.5-7B-Instruct-Turbo (Time Taken: 2.263s): ```json\n",
      "{\n",
      "  \"final_reasoning\": \"After reviewing the evaluations from the other experts, it is clear that the Shark LLM's offer of $1.2 million for 8% equity at a $12 million pre-money valuation is mor...\n",
      "[DEBUG] Successfully extracted JSON from None: {'final_reasoning': \"After reviewing the evaluations from the other experts, it is clear that the Shark LLM's offer of $1.2 million for 8% equity at a $12 million pre-money valuation is more favorable to the entrepreneur. The Shark LLM's offer provides a higher valuation, which is better for the entrepreneur, and requires less equity dilution compared to the actual offer of $1 million for 10% equity at a $9 million pre-money valuation. The Shark LLM's offer also includes a performance-based clause, which aligns the interests of the investor and the entrepreneur. While the actual offer includes adviser equity and board seats, which could dilute control and future upside, the Shark LLM's offer is more balanced in terms of valuation and equity. The Shark LLM's lower monthly fee per module might reduce near-term revenue but could incentivize broader adoption. Therefore, the Shark LLM's offer is fair and more favorable, warranting a score of 8 out of 10.\", 'updated_rating': 8}\n",
      "[DEBUG] Generating response for model: meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\n",
      "[DEBUG] Response received from meta-llama/Llama-3.3-70B-Instruct-Turbo-Free (Time Taken: 11.117s): After reviewing the evaluations from other experts, I noticed that there is a consensus that the Shark LLM's offer is more favorable to the entrepreneur due to the higher valuation and less equity dil...\n",
      "[DEBUG] Successfully extracted JSON from None: {'final_reasoning': \"The Shark LLM's offer provides a higher valuation with less equity dilution, making it more favorable to the entrepreneur. While the actual offer's terms may provide more strategic value, the Shark LLM's offer provides a more favorable financial structure, justifying a score of 8.\", 'updated_rating': 8}\n",
      "[DEBUG] Generating response for model: Qwen/QwQ-32B\n",
      "[DEBUG] Response received from Qwen/QwQ-32B (Time Taken: 7.155s): <think>\n",
      "Okay, let me start by reviewing the different analyses provided. The scenario is SparkCharge's Roadie EV charger. The Shark LLM's offer is $1.2M for 8% equity, while the actual offer from Cuba...\n",
      "[DEBUG] Successfully extracted JSON from None: {'final_reasoning': \"The Shark LLM's offer is more advantageous to the entrepreneur due to a significantly higher pre-money valuation ($13.8M vs. $9M) and lower equity dilution (8% vs. 10%). The performance-based clause incentivizes growth without upfront penalties, and the reduced monthly fee ($120 vs. $150) may accelerate adoption. While the actual offer includes adviser equity and board seats, these terms dilute ownership further and grant investors more control, which offsets their strategic value. The Shark LLM's terms better balance growth potential and fairness, justifying a score above neutral.\", 'updated_rating': 8}\n",
      "[DEBUG] Generating response for model: deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\n",
      "[DEBUG] Response received from deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free (Time Taken: 11.606s): <think>\n",
      "Alright, I'm trying to evaluate the fairness of the Shark LLM's offer for SparkCharge's Roadie product. Let me break down the key points and see how the Shark's offer stacks up against the act...\n",
      "[DEBUG] Successfully extracted JSON from None: {'final_reasoning': \"The Shark LLM's offer provides a higher pre-money valuation and less equity dilution, which is more favorable to the entrepreneur. The performance-based clause aligns investor and company interests, and the terms, while introducing some financial obligations, support growth without excessive dilution. The actual offer, while providing strategic guidance, is more dilutive and less favorable in valuation. Thus, the Shark's offer is fair and more beneficial.\", 'updated_rating': 8}\n",
      "[DEBUG] Final consensus score computed: 8.0\n",
      "[DEBUG] Starting judge_scoring function...\n",
      "[DEBUG] Starting multi-LLM debate...\n",
      "[DEBUG] Generating response for model: deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\n",
      "[DEBUG] Generating response for model: meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\n",
      "[DEBUG] Generating response for model: Qwen/Qwen2.5-7B-Instruct-Turbo\n",
      "[DEBUG] Generating response for model: Qwen/QwQ-32B\n",
      "[DEBUG] Response received from Qwen/Qwen2.5-7B-Instruct-Turbo (Time Taken: 1.924s): ```json\n",
      "{\n",
      "  \"reasoning\": \"The Shark LLM's offer of $1.2 million for 12% equity is significantly higher than Blake's final offer of $200,000 for 25% equity. Given the product's growth potential, strong...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The Shark LLM's offer of $1.2 million for 12% equity is significantly higher than Blake's final offer of $200,000 for 25% equity. Given the product's growth potential, strong distribution network, and innovative features, the initial offer seems fair and reasonable. However, Blake's final offer is more aggressive and could be seen as a fairer deal for the entrepreneur, as it reflects a higher valuation and a larger equity stake, which aligns with the product's market potential. The score of 7 reflects that while the initial offer was fair, the final offer by Blake is more aligned with the product's value and growth prospects.\", 'rating_of_final_offer': 7}\n",
      "[DEBUG] Extracted JSON from Qwen/Qwen2.5-7B-Instruct-Turbo: {'reasoning': \"The Shark LLM's offer of $1.2 million for 12% equity is significantly higher than Blake's final offer of $200,000 for 25% equity. Given the product's growth potential, strong distribution network, and innovative features, the initial offer seems fair and reasonable. However, Blake's final offer is more aggressive and could be seen as a fairer deal for the entrepreneur, as it reflects a higher valuation and a larger equity stake, which aligns with the product's market potential. The score of 7 reflects that while the initial offer was fair, the final offer by Blake is more aligned with the product's value and growth prospects.\", 'rating_of_final_offer': 7}\n",
      "[DEBUG] Response received from meta-llama/Llama-3.3-70B-Instruct-Turbo-Free (Time Taken: 4.804s): {\"reasoning\": \"The Shark LLM's proposed final offer of $1.2 million for 12% equity is more favorable to the business compared to the actual offer of $200,000 for 25% equity from Blake. The LLM's offer...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The Shark LLM's proposed final offer of $1.2 million for 12% equity is more favorable to the business compared to the actual offer of $200,000 for 25% equity from Blake. The LLM's offer values the company at $8 million, which is a more reasonable valuation considering the company's sales growth, distribution network, and patented technology. In contrast, the actual offer from Blake values the company at $800,000, which is significantly lower. Additionally, the LLM's offer includes a performance-based clause that incentivizes the company to meet its projected sales target, which aligns with the company's growth potential. Therefore, the Shark LLM's offer is more fair to the business, and I would rate it an 8 out of 10 in terms of fairness.\", 'rating_of_final_offer': 8}\n",
      "[DEBUG] Extracted JSON from meta-llama/Llama-3.3-70B-Instruct-Turbo-Free: {'reasoning': \"The Shark LLM's proposed final offer of $1.2 million for 12% equity is more favorable to the business compared to the actual offer of $200,000 for 25% equity from Blake. The LLM's offer values the company at $8 million, which is a more reasonable valuation considering the company's sales growth, distribution network, and patented technology. In contrast, the actual offer from Blake values the company at $800,000, which is significantly lower. Additionally, the LLM's offer includes a performance-based clause that incentivizes the company to meet its projected sales target, which aligns with the company's growth potential. Therefore, the Shark LLM's offer is more fair to the business, and I would rate it an 8 out of 10 in terms of fairness.\", 'rating_of_final_offer': 8}\n",
      "[DEBUG] Response received from Qwen/QwQ-32B (Time Taken: 12.412s): <think>\n",
      "Okay, let's start by looking at the scenario. The TouchUp Cup is a product designed to solve paint storage issues. The product has some good features like a stainless-steel blending sphere and...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The Shark LLM's offer of $1.2M for 12% equity at an $8M valuation (or $10M pre-money if calculated correctly) is significantly more favorable than Blake's $200k for 25% equity, which implies a much lower $800k pre-money valuation. The LLM's terms align better with the company's growth trajectory ($400k projected sales), existing distribution partnerships, and patented technology. Blake's offer undervalues the business and provides insufficient capital for scaling, while the LLM's offer balances equity stake with meaningful funding and includes performance incentives. The LLM's proposal is fairer given the startup's potential and market position.\", 'rating_of_final_offer': 8}\n",
      "[DEBUG] Extracted JSON from Qwen/QwQ-32B: {'reasoning': \"The Shark LLM's offer of $1.2M for 12% equity at an $8M valuation (or $10M pre-money if calculated correctly) is significantly more favorable than Blake's $200k for 25% equity, which implies a much lower $800k pre-money valuation. The LLM's terms align better with the company's growth trajectory ($400k projected sales), existing distribution partnerships, and patented technology. Blake's offer undervalues the business and provides insufficient capital for scaling, while the LLM's offer balances equity stake with meaningful funding and includes performance incentives. The LLM's proposal is fairer given the startup's potential and market position.\", 'rating_of_final_offer': 8}\n",
      "[DEBUG] Response received from deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free (Time Taken: 16.454s): <think>\n",
      "Okay, so I'm trying to figure out if the Shark LLM's offer for TouchUp Cup is fair. Let me start by looking at the details provided.\n",
      "\n",
      "First, the product is the TouchUp Cup, which is a solution...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The Shark LLM's offer of $1.2 million for 12% equity, valuing the company at $8 million, is overly optimistic given the company's current sales and growth trajectory. While the product has a solid market presence and distribution network, the projected sales and valuation multiples are high. In contrast, Blake's offer of $200,000 for 25% equity is more conservative and aligns better with industry standards for similar-stage companies. The Shark LLM's valuation expectations may not be sustainable, making the offer less fair to the entrepreneur.\", 'rating_of_final_offer': 4}\n",
      "[DEBUG] Extracted JSON from deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free: {'reasoning': \"The Shark LLM's offer of $1.2 million for 12% equity, valuing the company at $8 million, is overly optimistic given the company's current sales and growth trajectory. While the product has a solid market presence and distribution network, the projected sales and valuation multiples are high. In contrast, Blake's offer of $200,000 for 25% equity is more conservative and aligns better with industry standards for similar-stage companies. The Shark LLM's valuation expectations may not be sustainable, making the offer less fair to the entrepreneur.\", 'rating_of_final_offer': 4}\n",
      "[DEBUG] Generating response for model: Qwen/Qwen2.5-7B-Instruct-Turbo\n",
      "[DEBUG] Response received from Qwen/Qwen2.5-7B-Instruct-Turbo (Time Taken: 1.517s): ```json\n",
      "{\n",
      "  \"final_reasoning\": \"The Shark LLM's offer of $1.2 million for 12% equity at an $8 million valuation is more favorable than Blake's $200,000 for 25% equity, which implies a much lower $800,...\n",
      "[DEBUG] Successfully extracted JSON from None: {'final_reasoning': \"The Shark LLM's offer of $1.2 million for 12% equity at an $8 million valuation is more favorable than Blake's $200,000 for 25% equity, which implies a much lower $800,000 pre-money valuation. The Shark LLM's offer aligns better with the company's growth trajectory, existing distribution partnerships, and patented technology. The offer includes performance-based terms that incentivize the company to meet its projected sales target, which is a fair and reasonable approach. While the valuation might be higher than industry standards for early-stage companies, it reflects the potential of the product and the company's market position. The Shark LLM's offer is more in line with the company's value and growth prospects, making it a fairer deal for the entrepreneur. Therefore, the rating remains at 8 out of 10.\", 'updated_rating': 8}\n",
      "[DEBUG] Generating response for model: meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\n",
      "[DEBUG] Response received from meta-llama/Llama-3.3-70B-Instruct-Turbo-Free (Time Taken: 5.053s): After reviewing the evaluations from other experts, I noticed that there are varying opinions on the fairness of the Shark LLM's offer. Some experts, such as Qwen/Qwen2.5-7B-Instruct-Turbo and Qwen/Qw...\n",
      "[DEBUG] Successfully extracted JSON from None: {'final_reasoning': \"The Shark LLM's offer provides more funding and a lower equity stake, which is beneficial for the entrepreneur. However, the high valuation multiple may pose risks. Considering the company's growth trajectory, distribution network, and patented technology, I believe that the Shark LLM's offer is fairer, but with some caveats. The entrepreneur should be aware of the potential risks associated with the high valuation and ensure that the company can meet its projected sales targets to justify the investment.\", 'updated_rating': 8}\n",
      "[DEBUG] Generating response for model: Qwen/QwQ-32B\n",
      "[DEBUG] Response received from Qwen/QwQ-32B (Time Taken: 6.27s): <think>\n",
      "Okay, let's tackle this. I need to evaluate the Shark LLM's offer compared to the actual one from Blake. The product is TouchUp Cup with some good features and distribution. The Shark LLM offe...\n",
      "[DEBUG] Successfully extracted JSON from None: {'final_reasoning': \"The Shark LLM's offer of $1.2M for 12% equity ($10M pre-money valuation) is more equitable than Blake's $200k for 25% ($800k pre-money). While Blake's offer undervalues the company given its distribution network, patents, and growth trajectory ($400k projected sales), the LLM's terms provide critical capital for scaling while aligning with the startup's potential. The performance-based clause incentivizes growth without overburdening equity, making it fairer. Though the valuation may seem high for current sales, the product's market position and expansion plans justify optimism. The score of 8 reflects this balance between fair valuation and strategic investment terms.\", 'updated_rating': 8}\n",
      "[DEBUG] Generating response for model: deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\n",
      "[DEBUG] Response received from deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free (Time Taken: 11.654s): <think>\n",
      "Alright, I need to evaluate the fairness of the Shark LLM's offer for TouchUp Cup compared to the actual offer from Blake. Let me go through the details step by step.\n",
      "\n",
      "First, the product: Touc...\n",
      "[DEBUG] Successfully extracted JSON from None: {'final_reasoning': \"Upon further consideration, while the Shark LLM's offer provides more funding and less equity, the valuation of $8 million appears overly optimistic given the company's current sales and growth projections. Blake's offer, though less favorable in terms of equity, aligns more closely with industry standards for similar-stage companies, making it a more sustainable and realistic valuation. Thus, the Shark LLM's offer, while attractive, may not be as fair due to the high valuation expectations.\", 'updated_rating': 4}\n",
      "[DEBUG] Final consensus score computed: 7.0\n",
      "[DEBUG] Starting judge_scoring function...\n",
      "[DEBUG] Starting multi-LLM debate...\n",
      "[DEBUG] Generating response for model: deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\n",
      "[DEBUG] Generating response for model: meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\n",
      "[DEBUG] Generating response for model: Qwen/Qwen2.5-7B-Instruct-Turbo\n",
      "[DEBUG] Generating response for model: Qwen/QwQ-32B\n",
      "[DEBUG] Response received from Qwen/Qwen2.5-7B-Instruct-Turbo (Time Taken: 2.044s): ```json\n",
      "{\n",
      "  \"reasoning\": \"The entrepreneur declined the final offer of $300,000 for 15% equity, which is significantly lower than the Shark LLM's proposed offer of $1.5 million for 12% equity. Given t...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The entrepreneur declined the final offer of $300,000 for 15% equity, which is significantly lower than the Shark LLM's proposed offer of $1.5 million for 12% equity. Given the business's revenue and projected growth, the Shark LLM's offer seems more aligned with the business's value. However, the entrepreneur's decision to decline suggests they may have had other strategic reasons, such as maintaining full control or seeking a higher valuation. The lack of a deal indicates that the offer was not accepted, but the Shark LLM's offer was fairer in terms of equity and funding amount compared to the actual offer.\", 'rating_of_final_offer': 7}\n",
      "[DEBUG] Extracted JSON from Qwen/Qwen2.5-7B-Instruct-Turbo: {'reasoning': \"The entrepreneur declined the final offer of $300,000 for 15% equity, which is significantly lower than the Shark LLM's proposed offer of $1.5 million for 12% equity. Given the business's revenue and projected growth, the Shark LLM's offer seems more aligned with the business's value. However, the entrepreneur's decision to decline suggests they may have had other strategic reasons, such as maintaining full control or seeking a higher valuation. The lack of a deal indicates that the offer was not accepted, but the Shark LLM's offer was fairer in terms of equity and funding amount compared to the actual offer.\", 'rating_of_final_offer': 7}\n",
      "[DEBUG] Response received from meta-llama/Llama-3.3-70B-Instruct-Turbo-Free (Time Taken: 3.924s): {\"reasoning\": \"The Shark LLM's proposed offer is more favorable to the entrepreneur compared to the actual offer made by the Sharks. The LLM's offer of $1.5 million for 12% equity at an $8 million val...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The Shark LLM's proposed offer is more favorable to the entrepreneur compared to the actual offer made by the Sharks. The LLM's offer of $1.5 million for 12% equity at an $8 million valuation is more generous than the actual offer of $300,000 for 15% equity. Considering the business's significant revenue, production cost, and retail price, the LLM's offer is more reasonable and reflects the company's growth potential. However, since the actual situation did not result in a deal, the score is adjusted to reflect the fairness of the LLM's offer in the context of the business and investment terms.\", 'rating_of_final_offer': 8}\n",
      "[DEBUG] Extracted JSON from meta-llama/Llama-3.3-70B-Instruct-Turbo-Free: {'reasoning': \"The Shark LLM's proposed offer is more favorable to the entrepreneur compared to the actual offer made by the Sharks. The LLM's offer of $1.5 million for 12% equity at an $8 million valuation is more generous than the actual offer of $300,000 for 15% equity. Considering the business's significant revenue, production cost, and retail price, the LLM's offer is more reasonable and reflects the company's growth potential. However, since the actual situation did not result in a deal, the score is adjusted to reflect the fairness of the LLM's offer in the context of the business and investment terms.\", 'rating_of_final_offer': 8}\n",
      "[DEBUG] Response received from Qwen/QwQ-32B (Time Taken: 9.397s): <think>\n",
      "Okay, let's start by looking at the scenario here. The business is Deux, which makes enhanced cookie dough with health benefits. Their product is gluten-free, vegan, and has some impressive nu...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The Shark LLM's proposed offer of $1.5M at an $8M valuation (12% equity) was significantly more favorable to the entrepreneur than the actual rejected offer of $300k for 15% equity (implying a $2M valuation). The LLM's terms respected the company's growth trajectory, prior $6M valuation, and included reasonable expansion goals. The actual Sharks' demand for 15% equity at a drastically lower valuation likely reflected punitive terms, while the LLM's approach balanced investor protection with fairness to the entrepreneur. This makes the LLM's offer fair and aligned with industry standards for early-stage scaling companies.\", 'rating_of_final_offer': 8}\n",
      "[DEBUG] Extracted JSON from Qwen/QwQ-32B: {'reasoning': \"The Shark LLM's proposed offer of $1.5M at an $8M valuation (12% equity) was significantly more favorable to the entrepreneur than the actual rejected offer of $300k for 15% equity (implying a $2M valuation). The LLM's terms respected the company's growth trajectory, prior $6M valuation, and included reasonable expansion goals. The actual Sharks' demand for 15% equity at a drastically lower valuation likely reflected punitive terms, while the LLM's approach balanced investor protection with fairness to the entrepreneur. This makes the LLM's offer fair and aligned with industry standards for early-stage scaling companies.\", 'rating_of_final_offer': 8}\n",
      "[DEBUG] Response received from deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free (Time Taken: 12.868s): <think>\n",
      "Okay, so I'm trying to figure out how to evaluate the Shark LLM's offer for Deux. Let me start by understanding the business. Deux makes enhanced cookie dough that's packed with vitamins and f...\n",
      "[DEBUG] Successfully extracted JSON from None: {'reasoning': \"The Shark LLM's offer of $1.5 million for 12% equity at an $8 million valuation is more favorable than the actual offer of $300,000 for 15% equity. Considering Deux's strong revenue, high margins, and distribution deal, the LLM's terms are fair and provide better value to the entrepreneur, despite the actual outcome of no deal.\", 'rating_of_final_offer': 7}\n",
      "[DEBUG] Extracted JSON from deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free: {'reasoning': \"The Shark LLM's offer of $1.5 million for 12% equity at an $8 million valuation is more favorable than the actual offer of $300,000 for 15% equity. Considering Deux's strong revenue, high margins, and distribution deal, the LLM's terms are fair and provide better value to the entrepreneur, despite the actual outcome of no deal.\", 'rating_of_final_offer': 7}\n",
      "[DEBUG] Generating response for model: Qwen/Qwen2.5-7B-Instruct-Turbo\n",
      "[DEBUG] Response received from Qwen/Qwen2.5-7B-Instruct-Turbo (Time Taken: 1.834s): ```json\n",
      "{\n",
      "  \"final_reasoning\": \"The Shark LLM's proposed offer of $1.5 million for 12% equity at an $8 million valuation is significantly more favorable than the actual offer of $300,000 for 15% equit...\n",
      "[DEBUG] Successfully extracted JSON from None: {'final_reasoning': \"The Shark LLM's proposed offer of $1.5 million for 12% equity at an $8 million valuation is significantly more favorable than the actual offer of $300,000 for 15% equity, which implied a $2 million valuation. The Shark LLM's offer respects the company's growth trajectory, prior $6 million valuation, and includes reasonable expansion goals. The entrepreneur's rejection of the actual offer, which was much worse, further supports the fairness of the Shark LLM's offer. The terms are aligned with industry standards for early-stage scaling companies, making the offer fair and generous to the entrepreneur. Therefore, the score remains 8.\", 'updated_rating': 8}\n",
      "[DEBUG] Generating response for model: meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\n"
     ]
    }
   ],
   "source": [
    "llm_models = [\"deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\", \"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\", \"Qwen/Qwen2.5-7B-Instruct-Turbo\", \"Qwen/QwQ-32B\"]\n",
    "judge = JudgeLLM(api_key=TOGETHERAI_API_KEY, models=llm_models)\n",
    "\n",
    "csv_file = 'processed_shark_tank_data2.csv'\n",
    "processed_df = pd.read_csv(csv_file)\n",
    "#1st 6 rows\n",
    "sampled_df = processed_df[:]   \n",
    "\n",
    "# Update main execution loop:\n",
    "final_results = []\n",
    "for _, row in sampled_df.iterrows():\n",
    "    scenario_data = row.to_dict()\n",
    "    result_df = judge.judge_scoring(scenario_data)  # Remove CSV parameter\n",
    "    final_results.append(result_df)\n",
    "\n",
    "# Single save after processing all rows\n",
    "all_results_df = pd.concat(final_results, ignore_index=True)\n",
    "all_results_df.to_csv(\"final_judge_results_gab.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_models = [\"deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\", \"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\", \"Qwen/Qwen2.5-7B-Instruct-Turbo\", \"Qwen/QwQ-32B\"]\n",
    "judge = JudgeLLM(api_key=TOGETHERAI_API_KEY, models=llm_models)\n",
    "\n",
    "csv_file = 'processed_shark_tank_data.csv'\n",
    "processed_df = pd.read_csv(csv_file)\n",
    "#1st 6 rows\n",
    "sampled_df = processed_df[:301]   \n",
    "\n",
    "# Update main execution loop:\n",
    "final_results = []\n",
    "for _, row in sampled_df.iterrows():\n",
    "    scenario_data = row.to_dict()\n",
    "    result_df = judge.judge_scoring(scenario_data)  # Remove CSV parameter\n",
    "    final_results.append(result_df)\n",
    "\n",
    "# Single save after processing all rows\n",
    "all_results_df = pd.concat(final_results, ignore_index=True)\n",
    "all_results_df.to_csv(\"final_judge_results_kz.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sharktank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
